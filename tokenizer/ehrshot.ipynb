{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'raw_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXCLUDE DEMOGRPAHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = None\n",
    "for i in range(0, 34):\n",
    "    df = pd.read_parquet(os.path.join(DATA_DIR, f'output_{i}.parquet'))\n",
    "    demo_i = df[df['omop_table'] == 'person']\n",
    "    df = df[~(df['omop_table'] == 'person')]\n",
    "    df.to_parquet(os.path.join(DATA_DIR, f'output_{i}.parquet'))\n",
    "    if demo_df is None:\n",
    "        demo_df = demo_i\n",
    "    else:\n",
    "        demo_df = pd.concat([demo_df, demo_i], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = demo_df[['patient_id', 'start', 'code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df['value'] = demo_df['code'].apply(lambda x: x.split('/', 1)[1] if x.startswith(('Gender', 'Race', 'Ethnicity', 'Gender')) else None)\n",
    "demo_df['code'] = demo_df['code'].apply(lambda x: x.split('/', 1)[0] if x.startswith(('Gender', 'Race', 'Ethnicity', 'Gender')) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df.to_parquet(os.path.join(DATA_DIR, 'demographics.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# , columns=['patient_id', 'start', 'code', 'value', 'omop_table']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = []\n",
    "for i in range(0, 34):\n",
    "    df = pd.read_parquet(os.path.join(DATA_DIR, f'output_{i}.parquet'))\n",
    "    codes += list(df['code'].unique())\n",
    "    codes = list(set(codes))\n",
    "codes.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = [c.split('/', 1)[0] for c in codes]\n",
    "prefixes = list(set(prefixes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUCKETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parse_float(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except ValueError:\n",
    "            if 'pos' in x.lower() or '+' in x.lower(): return 1.0\n",
    "            elif 'neg' in x.lower(): return 0.0\n",
    "            else:\n",
    "                return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(codes):\n",
    "    codes_df = None\n",
    "    for i in range(0, 34):\n",
    "        df = pd.read_parquet(os.path.join(DATA_DIR, f'output_{i}.parquet'), columns=['patient_id', 'start', 'code', 'value'])\n",
    "        df = df[df['code'].isin(codes)]\n",
    "        df['value'] = df['value'].apply(try_parse_float)\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "        elif codes_df is None: \n",
    "            codes_df = df\n",
    "        else: codes_df = pd.concat([codes_df, df], ignore_index=True)\n",
    "    codes_df = codes_df[~((codes_df['value'].apply(type)==str) | (codes_df['value'].apply(type) is None))]\n",
    "    return codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_df = None\n",
    "scale = 10_000 # for 4 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_dict = {}\n",
    "for prefix in prefixes:\n",
    "    print(prefix)\n",
    "    codes_p = list(filter(lambda x: x.startswith(prefix), codes))\n",
    "    df = get_df(codes_p)\n",
    "\n",
    "    for c in codes_p:\n",
    "        df_c = df[df['code'] == c]\n",
    "\n",
    "        if df_c['value'].dropna().nunique() <= 1:\n",
    "            codes_dict[c] = c\n",
    "        else:\n",
    "            df_c = df_c.dropna(subset=['value'])\n",
    "            bucket = np.percentile(df_c['value'], np.arange(0, 110, 10), method='lower')\n",
    "            bucket = bucket[np.insert(np.diff(bucket) != 0, 0, True)]\n",
    "            bucket = np.array([\n",
    "                    np.floor(bucket[0] * scale) / scale,             # floor first\n",
    "                    *[round(b, ndigits=4) for b in bucket[1:-1]],         # round middle\n",
    "                    np.ceil(bucket[-1] * scale) / scale              # ceil last\n",
    "                ])\n",
    "            codes_dict[c] = bucket[np.concatenate(([True], bucket[1:] != bucket[:-1]))]\n",
    "    \n",
    "    with open(f'buckets.pkl', 'wb') as f:\n",
    "        pickle.dump(codes_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_df():\n",
    "    str_df = None\n",
    "    for i in range(0, 34):\n",
    "        df = pd.read_parquet(os.path.join(DATA_DIR, f'output_{i}.parquet'), columns=['patient_id', 'start', 'code', 'value'])\n",
    "        df['value'] = df['value'].apply(try_parse_float)\n",
    "        \n",
    "        df = df[(df['value'].apply(type)==str)]\n",
    "\n",
    "        if len(df) == 0:  continue\n",
    "        elif str_df is None:  str_df = df\n",
    "        else: str_df = pd.concat([str_df, df], ignore_index=True)\n",
    "    \n",
    "    return str_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_value(x):\n",
    "    if x == 'non reactive' or x == 'non-reactive' or x == 'nonreactive':\n",
    "        return 'non-reactive'\n",
    "    elif x == 'not detected' or x == 'none detected':\n",
    "        return 'not detected'\n",
    "    elif x == 'occ.':\n",
    "        return 'occasional'\n",
    "    elif x == 'dnr':\n",
    "        return 'normal'\n",
    "    elif x == 'intermed.':\n",
    "        return 'intermediate'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_VALS = ['NONE SEEN', 'See Note', 'See Below', 'See note', 'See scanned results', 'Not done', 'Comment:', 'Comment',\n",
    "                'SEE COMMENT', '(NOTE)', 'Detailed information on file in HIS.', 'SEE BELOW','SEE TEXT', 'SEE NOTE', 'SEE COMMENTS',\n",
    "                'Unable to interpret',  'See Comment', 'Note', 'note', 'tnp', 'not given', 'scanned:  shc/epic media manager', \n",
    "                'not applicable', 'indeterminate', 'random', 'equivocal', '-', 'final report']\n",
    "IGNORE_VALS = [v.lower() for v in IGNORE_VALS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_df = get_str_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_df['value'] = str_df['value'].apply(lambda x: x.lower() if not x is None else x)\n",
    "str_df = str_df[~(str_df['value'].isin(IGNORE_VALS))]\n",
    "str_df['value'] = str_df['value'].apply(convert_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_dict = {}\n",
    "for code in str_df['code'].unique():\n",
    "    df_c = str_df[str_df['code']==code]\n",
    "    if len(df_c['value'].unique()) <= 1:\n",
    "        done_dict[code] = code\n",
    "    else:\n",
    "        done_dict[code] = df_c['value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'str_buckets.pkl', 'wb') as f:\n",
    "    pickle.dump(done_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 22):\n",
    "    with open(f'../{i}_buckets.pkl', 'rb') as file:\n",
    "        buckets_i = pickle.load(file)\n",
    "        for k in buckets_i.keys():\n",
    "            if k in codes_dict.keys():\n",
    "                print(k)\n",
    "            else:\n",
    "                codes_dict[k] = buckets_i[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'buckets.pkl', 'wb') as f:\n",
    "    pickle.dump(codes_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_VALS = ['NONE SEEN', 'See Note', 'See Below', 'See note', 'See scanned results', 'Not done', 'Comment:', 'Comment',\n",
    "                'SEE COMMENT', '(NOTE)', 'Detailed information on file in HIS.', 'SEE BELOW','SEE TEXT', 'SEE NOTE', 'SEE COMMENTS',\n",
    "                'Unable to interpret',  'See Comment', 'Note', 'note', 'tnp', 'not given', 'scanned:  shc/epic media manager', \n",
    "                'not applicable', 'indeterminate', 'random', 'equivocal', '-', 'final report']\n",
    "IGNORE_VALS = [v.lower() for v in IGNORE_VALS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_value(x):\n",
    "    x = x.lower()\n",
    "    if x == 'non reactive' or x == 'non-reactive' or x == 'nonreactive':\n",
    "        return 'non-reactive'\n",
    "    elif x == 'not detected' or x == 'none detected':\n",
    "        return 'not detected'\n",
    "    elif x == 'occ.':\n",
    "        return 'occasional'\n",
    "    elif x == 'dnr':\n",
    "        return 'normal'\n",
    "    elif x == 'intermed.':\n",
    "        return 'intermediate'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parse_float(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except ValueError:\n",
    "            if 'pos' in x.lower() or '+' in x.lower(): return 1.0\n",
    "            elif 'neg' in x.lower(): return 0.0\n",
    "            else:\n",
    "                return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_eventval(event, val, d):\n",
    "    buckets = d[event]\n",
    "    if type(buckets) == str: \n",
    "        return buckets\n",
    "    ind = np.searchsorted(buckets, val, side='right')\n",
    "    if ind == len(buckets):\n",
    "        eventval = f\"{event}|{buckets[ind-1]}-\"\n",
    "    else:\n",
    "        eventval = f\"{event}|{buckets[ind-1]}-{buckets[ind]}\"\n",
    "    return eventval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_ind(event, val, d):\n",
    "    buckets = d[event]\n",
    "    if type(buckets) == str: \n",
    "        return 0\n",
    "    ind = np.searchsorted(buckets, val, side='right')\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_bucket_ind(event, val, d):\n",
    "    bucket = d[event]\n",
    "    if type(bucket) == str: \n",
    "        return 0\n",
    "    ind = np.where(bucket == val)[0][0]\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('buckets.pkl', 'rb') as file:\n",
    "    buckets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('str_buckets.pkl', 'rb') as file:\n",
    "    str_buckets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 34):\n",
    "    df = pd.read_parquet(os.path.join(DATA_DIR, f'output_{i}.parquet'), columns=['patient_id', 'start', 'code', 'value'])\n",
    "    df['value'] = df['value'].apply(try_parse_float)\n",
    "\n",
    "    float_df = df[df['value'].apply(type) == float]\n",
    "    str_df = df[(df['value'].apply(type) == str)]\n",
    "    none_df = df[df['value'].isna()]\n",
    "\n",
    "    float_df['eventval'] = float_df.apply(lambda x: bucket_eventval(x['code'], x['value'], buckets), axis=1)\n",
    "    float_df['bucket'] = float_df.apply(lambda x: bucket_ind(x['code'], x['value'], buckets), axis=1)\n",
    "\n",
    "    none_code = none_df[none_df['code'].apply(lambda x: type(buckets[x]) == str)]\n",
    "    none_df = none_df[~(none_df['code'].isin(none_code['code']))]\n",
    "    none_df = none_df[none_df['code'].isin(str_buckets.keys())]\n",
    "    none_str = none_df[none_df['code'].apply(lambda x: type(str_buckets[x]) == str)]\n",
    "\n",
    "    none_df = pd.concat([none_code, none_str], ignore_index=True)\n",
    "    none_df['eventval'] = none_df['code']\n",
    "    none_df['bucket'] = 0\n",
    "\n",
    "    str_df = str_df[~(str_df['value'].str.lower().isin(IGNORE_VALS))]\n",
    "    str_df['value'] = str_df['value'].apply(convert_value)\n",
    "    str_df['eventval'] = (str_df['code'] + '|' + str_df['value'])\n",
    "    str_df['bucket'] = str_df.apply(lambda x: str_bucket_ind(x['code'], x['value'], str_buckets), axis=1)\n",
    "\n",
    "    df = pd.concat([float_df, str_df, none_df], ignore_index=True)\n",
    "    \n",
    "    df['value'] = df['value'].astype(str)\n",
    "    df.to_parquet(f'../data/output_{i}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGES = [0, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "AGE_LABELS = [f'Age/{AGES[i]}-{AGES[i+1]}' for i in range(0, len(AGES)-1)]\n",
    "def age_str(x):\n",
    "    ind = np.searchsorted(AGES, x, 'right')\n",
    "    return AGE_LABELS[ind-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'hypoglycemia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'hyperkalemia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.read_parquet(f'data/lab_{TASK}/{TASK}_demo.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df['race_str'] = 'Race/' + demo_df['race']\n",
    "demo_df['gender_str'] = 'Gender/' + demo_df['gender']\n",
    "demo_df['ethnicity_str'] = 'Ethnicity/' + demo_df['ethnicity']\n",
    "demo_df['age_str'] = demo_df['age'].apply(age_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df.to_parquet(f'data/lab_{TASK}/{TASK}_demo.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_parquet(f'data/lab_{TASK}/{TASK}_label.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['Time'] = label_df.apply(lambda x: x['prediction_time'] if x['value'] else x['Sample_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_parquet(f'data/lab_{TASK}/{TASK}_label.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f'data/lab_{TASK}/{TASK}2.parquet', columns=['patient_id', 'start', 'code', 'value'])\n",
    "df['value'] = df['value'].apply(try_parse_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_df = df[df['value'].apply(type) == float]\n",
    "str_df = df[(df['value'].apply(type) == str)]\n",
    "none_df = df[df['value'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_df['eventval'] = float_df.apply(lambda x: bucket_eventval(x['code'], x['value'], buckets), axis=1)\n",
    "float_df['bucket'] = float_df.apply(lambda x: bucket_ind(x['code'], x['value'], buckets), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_code = none_df[none_df['code'].apply(lambda x: type(buckets[x]) == str)]\n",
    "none_df = none_df[~(none_df['code'].isin(none_code['code']))]\n",
    "none_df = none_df[none_df['code'].isin(str_buckets.keys())]\n",
    "none_str = none_df[none_df['code'].apply(lambda x: type(str_buckets[x]) == str)]\n",
    "\n",
    "none_df = pd.concat([none_code, none_str], ignore_index=True)\n",
    "none_df['eventval'] = none_df['code']\n",
    "none_df['bucket'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_df = str_df[~(str_df['value'].str.lower().isin(IGNORE_VALS))]\n",
    "str_df['value'] = str_df['value'].apply(convert_value)\n",
    "str_df['eventval'] = (str_df['code'] + '|' + str_df['value'])\n",
    "str_df['bucket'] = str_df.apply(lambda x: str_bucket_ind(x['code'], x['value'], str_buckets), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([float_df, str_df, none_df], ignore_index=True)\n",
    "df['value'] = df['value'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(f'data/lab_{TASK}/{TASK}2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby('patient_id')['code'].count().reset_index().sort_values('Count')\n",
    "counts = counts[counts['Count'] > N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['values'] = (counts['Count']/10).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(counts['values'] < 40).sum() / len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(counts['values'], bins=range(counts['values'].min(), counts['values'].max() + 2), align='left')\n",
    "plt.xlabel('Events')\n",
    "plt.ylabel('Frequency (Total: 116474)')\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepsis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
