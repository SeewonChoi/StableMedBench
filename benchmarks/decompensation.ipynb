{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b03800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patients who will experience clinical deterioration\n",
    "# new onset among patients with initially normal vital signs (first 15 minutes)\n",
    "\n",
    "# tachycardia: HR > 110\n",
    "# hypotension: MAP < 65\n",
    "# hypoxia: SpO2 < 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73f12ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98fd275",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mkeoliya/projects/mc-med/mc-med-1.0.0/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68db0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLS = ['HR', 'RR', 'SpO2', 'SBP', 'DBP', 'MAP', 'Temp', 'Perf'] # Pain HRV, LPM_O2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b09e9",
   "metadata": {},
   "source": [
    "EXCLUDE INITIALLY SICK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca9889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_cols = ['MRN', 'CSN', #'Age', 'Gender', 'Race', 'Ethnicity', \n",
    "               'Triage_HR', 'Triage_SpO2', 'CC', 'Dx_ICD10', 'Dx_name',\n",
    "               'Arrival_time', 'Roomed_time', 'Dispo_time', 'Admit_time', 'Departure_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18698ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df = pd.read_csv(os.path.join(DATA_DIR, 'visits.csv'), usecols=visits_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4832f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df['Arrival_time'] = pd.to_datetime(visits_df['Arrival_time'].apply(lambda x: str(int(x[:4]) - 500) + x[4:]))\n",
    "# visits_df['Roomed_time'] = pd.to_datetime(visits_df['Roomed_time'].apply(lambda x: str(int(x[:4]) - 500) + x[4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2815b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_df = visits_df[['CSN', 'Triage_HR', 'Triage_SpO2']]\n",
    "triage_df = triage_df[(triage_df['Triage_HR'] > 110) | (triage_df['Triage_SpO2'] < 90)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93be16",
   "metadata": {},
   "source": [
    "EXCLUDE INITIALLY SICK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "700e6489",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 90 # MINUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df48810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_df = pd.read_csv(os.path.join(DATA_DIR, 'numerics.csv'))\n",
    "numerics_df = numerics_df[~numerics_df['CSN'].isin(triage_df['CSN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "926f7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_df['Time'] = pd.to_datetime(numerics_df['Time'].apply(lambda x: str(int(x[:4]) - 500) + x[4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c9fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = numerics_df.merge(visits_df[['CSN', 'Arrival_time', 'Roomed_time']], on='CSN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8302ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = initial_df[initial_df['Time'] <= initial_df['Arrival_time'] + pd.Timedelta(minutes=N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8adfc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = initial_df[((initial_df['Measure'] == 'HR') & (initial_df['Value'] > 110))\n",
    "                        |(initial_df['Measure'] == 'MAP') & (initial_df['Value'] < 65)\n",
    "                        |(initial_df['Measure'] == 'SpO2') & (initial_df['Value'] < 90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "611a99f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_df = numerics_df[~numerics_df['CSN'].isin(initial_df['CSN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f846bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79948"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics_df['CSN'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d08ca",
   "metadata": {},
   "source": [
    "EXCLUDE FEW EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ddb27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_counts = numerics_df.groupby('CSN')['Measure'].unique()\n",
    "csns_with_many_measures = measure_counts.apply(lambda x: set(list(x)).issuperset(set(NUM_COLS))).index\n",
    "numerics_df = numerics_df[numerics_df['CSN'].isin(csns_with_many_measures)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bb04720",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_counts = numerics_df.groupby('CSN')['Measure'].count()\n",
    "csns_with_many_measures = measure_counts[measure_counts >= 10].index\n",
    "numerics_df = numerics_df[numerics_df['CSN'].isin(csns_with_many_measures)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1955037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75531"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics_df['CSN'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f8bbe",
   "metadata": {},
   "source": [
    "POSITIVE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "930ecb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_df = numerics_df[(numerics_df['Measure'] == 'HR') & (numerics_df['Value'] > 110)]\n",
    "MAP_df = numerics_df[(numerics_df['Measure'] == 'MAP') & (numerics_df['Value'] < 65)]\n",
    "SpO2_df = numerics_df[(numerics_df['Measure'] == 'SpO2') & (numerics_df['Value'] < 90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def370c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2353447/612074950.py:2: FutureWarning: The provided callable <built-in function min> is currently using DataFrameGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  pos_df = pos_df[['CSN', 'Time']].groupby('CSN').agg(min).reset_index().rename(columns={'Time': 'Criteria_time'})\n"
     ]
    }
   ],
   "source": [
    "pos_df = pd.concat([HR_df, MAP_df, SpO2_df])\n",
    "pos_df = pos_df[['CSN', 'Time']].groupby('CSN').agg(min).reset_index().rename(columns={'Time': 'Criteria_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7256100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10863\n"
     ]
    }
   ],
   "source": [
    "print(pos_df['CSN'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768aa152",
   "metadata": {},
   "source": [
    "CREATE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f776af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = visits_df[['CSN', 'Arrival_time', 'Roomed_time']]\n",
    "df = df[df['CSN'].isin(numerics_df['CSN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "940912b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(pos_df, on='CSN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e38445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = ~df['Criteria_time'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e8ecc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Criteria_from_arrive'] = (df['Criteria_time'] - df['Arrival_time']).dt.total_seconds() / 3600\n",
    "# df['Criteria_from_room'] = (df['Criteria_time'] - df['Roomed_time']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18f99b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Arrival_time', 'Roomed_time', 'Criteria_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79031cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"data/decompensation.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ae2a1",
   "metadata": {},
   "source": [
    "NEG SAMPLE TIMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2eecef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = df[df['Label'] == False]\n",
    "pos_df = df[df['Label'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96910832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01c41fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2353447/1438893731.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_df['Sample_time'] = kde.resample(size=len(neg_df)).flatten()\n"
     ]
    }
   ],
   "source": [
    "original = (pos_df['Criteria_from_arrive'].values)\n",
    "kde = gaussian_kde(original)\n",
    "neg_df['Sample_time'] = kde.resample(size=len(neg_df)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd8423f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.concat([neg_df, pos_df])\n",
    "df = df.merge(label_df[['CSN', 'Sample_time']], on='CSN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d1f5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"data/decompensation.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ed722",
   "metadata": {},
   "source": [
    "SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fdf9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad31c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.4, random_state=1234)\n",
    "X_test, X_val = train_test_split(X_test, test_size=0.5, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_parquet('data/decomp_train.parquet')\n",
    "X_val.to_parquet('data/decomp_val.parquet')\n",
    "X_test.to_parquet('data/decomp_test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041244f",
   "metadata": {},
   "source": [
    "ADD NUMERICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26682985",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_parquet('data/decompensation.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eae1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_NAME = ['event', 'time', 'value']\n",
    "COLS = {\n",
    "    \"labs\": ['Component_name', 'Order_time', 'Component_value'],\n",
    "    \"numerics\": ['Measure', 'Time', 'Value'],\n",
    "    \"orders\": ['Procedure_ID', 'Order_time'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2939e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parse_float(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            x = x.lstrip('<>=').strip()\n",
    "            x = x.replace(',', ':')\n",
    "            if ':' in x:\n",
    "                try:\n",
    "                    num, denom = x.split(':')\n",
    "                    return float(num) / float(denom)\n",
    "                except (ValueError, ZeroDivisionError):\n",
    "                    return x\n",
    "            return float(x)\n",
    "        except ValueError:\n",
    "            return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e09ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_fn(fn, label_df):\n",
    "    cols = COLS[fn]\n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, f'{fn}.csv'), usecols=['CSN'] + cols)\n",
    "    df = df[df['CSN'].isin(label_df['CSN'])]\n",
    "    df = df.rename(columns={c: COLS_NAME[i] for i, c in enumerate(cols)})\n",
    "    df = df.dropna()\n",
    "    df['event'] = df['event'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3166fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_eventval(event, val, d):\n",
    "    buckets = d[event]\n",
    "    ind = np.searchsorted(buckets, val, side='right')\n",
    "    if ind == len(buckets):\n",
    "        eventval = f\"{event}|{buckets[ind-1]}-\"\n",
    "    else:\n",
    "        eventval = f\"{event}|{buckets[ind-1]}-{buckets[ind]}\"\n",
    "    return eventval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2cf77e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_ind(event, val, d):\n",
    "    buckets = d[event]\n",
    "    ind = np.searchsorted(buckets, val, side='right')\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f15ed4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df():\n",
    "    visits_df = pd.read_csv(os.path.join(DATA_DIR, 'visits.csv'), usecols=['CSN', 'Arrival_time', 'Roomed_time']) # 'Age', 'Gender', 'Race', 'Ethnicity'\n",
    "\n",
    "    vitals_df = read_csv_fn('numerics', label_df)\n",
    "    # vitals_df = vitals_df[vitals_df['event'].isin(NUM_COLS)]\n",
    "    \n",
    "    with open('next_token/numerics_buckets.pkl', 'rb') as f:\n",
    "        buckets = pickle.load(f)\n",
    "    vitals_df['eventval'] = vitals_df.apply(lambda x: bucket_eventval(x['event'], x['value'], buckets), axis=1)\n",
    "    vitals_df['buckets'] = vitals_df.apply(lambda x: bucket_ind(x['event'], x['value'], buckets), axis=1)\n",
    "\n",
    "    df = vitals_df.merge(visits_df, on='CSN', how='left')\n",
    "\n",
    "    df['time'] = df['time'].apply(lambda x: str(int(x[:4]) - 500) + x[4:])\n",
    "    df['Arrival_time'] = df['Arrival_time'].apply(lambda x: str(int(x[:4]) - 500) + x[4:])\n",
    "    df['Roomed_time'] = df['Roomed_time'].apply(lambda x: str(int(x[:4]) - 500) + x[4:])\n",
    "\n",
    "    df['time_arrive'] = pd.to_datetime(df['time']) - pd.to_datetime(df['Arrival_time'])\n",
    "    df['time_arrive'] = df['time_arrive'].dt.total_seconds() / 3600\n",
    "\n",
    "    df['time_room'] = pd.to_datetime(df['time']) - pd.to_datetime(df['Roomed_time'])\n",
    "    df['time_room'] = df['time_room'].dt.total_seconds() / 3600\n",
    "\n",
    "    df = df.drop(columns=['Arrival_time', 'Roomed_time', 'time'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "396ac36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c449c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"data/decompensation_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbdbc8",
   "metadata": {},
   "source": [
    "ADD OTHER EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e62ad37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df():\n",
    "    visits_df = pd.read_csv(os.path.join(DATA_DIR, 'visits.csv'), usecols=['CSN', 'Arrival_time', 'Roomed_time']) # 'Age', 'Gender', 'Race', 'Ethnicity'\n",
    "\n",
    "    vitals_df = read_csv_fn('numerics', label_df)\n",
    "    with open('next_token/numerics_buckets.pkl', 'rb') as f:\n",
    "        buckets = pickle.load(f)\n",
    "    vitals_df['eventval'] = vitals_df.apply(lambda x: bucket_eventval(x['event'], x['value'], buckets), axis=1)\n",
    "    vitals_df['buckets'] = vitals_df.apply(lambda x: bucket_ind(x['event'], x['value'], buckets), axis=1)\n",
    "\n",
    "    labs_df = read_csv_fn('labs', label_df)\n",
    "    labs_df['value'] = labs_df['value'].replace([None], 0.0).apply(try_parse_float)\n",
    "    labs_df['value'] = labs_df['value'].apply(lambda x: 0.0 if isinstance(x, str) and 'pos' in x.lower() else x)\n",
    "    labs_df['value'] = labs_df['value'].apply(lambda x: 1.0 if isinstance(x, str) and (any(sub in x.lower() for sub in ['neg', 'not', 'none', 'auto'])) else x)\n",
    "\n",
    "    with open('next_token/labs_buckets.pkl', 'rb') as f:\n",
    "        buckets = pickle.load(f)\n",
    "    labs_df['eventval'] = labs_df.apply(lambda x: bucket_eventval(x['event'], x['value'], buckets), axis=1)\n",
    "    labs_df['buckets'] = labs_df.apply(lambda x: bucket_ind(x['event'], x['value'], buckets), axis=1)\n",
    "\n",
    "    orders_df = read_csv_fn('orders', label_df)\n",
    "    orders_df['value'] = 0\n",
    "    orders_df['buckets'] = 0\n",
    "    orders_df['eventval'] = orders_df['event']\n",
    "\n",
    "    df = pd.concat([labs_df, vitals_df, orders_df])\n",
    "    df = df.merge(visits_df, on='CSN', how='left')\n",
    "\n",
    "    df['time'] = df['time'].apply(lambda x: str(int(x[:4]) - 500) + x[4:])\n",
    "    df['Arrival_time'] = df['Arrival_time'].apply(lambda x: str(int(x[:4]) - 500) + x[4:])\n",
    "    df['Roomed_time'] = df['Roomed_time'].apply(lambda x: str(int(x[:4]) - 500) + x[4:])\n",
    "\n",
    "    df['time_arrive'] = pd.to_datetime(df['time']) - pd.to_datetime(df['Arrival_time'])\n",
    "    df['time_arrive'] = df['time_arrive'].dt.total_seconds() / 3600\n",
    "\n",
    "    df['time_room'] = pd.to_datetime(df['time']) - pd.to_datetime(df['Roomed_time'])\n",
    "    df['time_room'] = df['time_room'].dt.total_seconds() / 3600\n",
    "\n",
    "    df = df.drop(columns=['Arrival_time', 'Roomed_time', 'time'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d86aa563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae0775f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"data/decomp_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19751592",
   "metadata": {},
   "source": [
    "UPDATE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a7559fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'eSOFA' # 'eSOFA' 'decompensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f084056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f'data/{TASK}_demo.parquet')\n",
    "label_df = pd.read_parquet(f'data/{TASK}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed58280",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['Time'] = label_df.apply(lambda x: x['Trigger_time'] if x['Label'] else x['Sample_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ff611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender_ind'] = pd.factorize(df['Gender'])[0]\n",
    "df['Race_ind'] = pd.factorize(df['Race'])[0]\n",
    "df['Ethnicity_ind'] = pd.factorize(df['Ethnicity'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdec097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Race_str'] = 'Race|' + df['Race']\n",
    "df['Ethnicity_str'] = 'Ethnicity|' + df['Ethnicity']\n",
    "df['Gender_str'] = 'Gender|' + df['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "243ecece",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "labels = ['0-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90']\n",
    "df['Age_str'] = pd.cut(df['Age'], bins=bins, labels=labels, right=True, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6499493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(f'data/{TASK}_demo.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40379f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_parquet(f'data/{TASK}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc1f6cf",
   "metadata": {},
   "source": [
    "ADD CRITERIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96021cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('next_token/numerics_buckets.pkl', 'rb') as f:\n",
    "        buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_bucket = np.searchsorted(buckets['HR'], 110, side='right')\n",
    "map_bucket = np.searchsorted(buckets['MAP'], 65, side='right')\n",
    "SpO2_bucket = np.searchsorted(buckets['SpO2'], 90, side='right')\n",
    "print(hr_bucket, map_bucket, SpO2_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03ada090",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_buckets = [10, 11]\n",
    "map_bucket = [1]\n",
    "SpO2_buckets = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "458c3f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['HR|106.0667-268.0', 'HR|268.0-'], ['MAP|1.0-75.6667'], ['SpO2|0.0-94.7907'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_criteria, map_criteria, spo2_criteria = [], [], []\n",
    "for inds, event, criteria in [(hr_buckets, 'HR', hr_criteria), (map_bucket, 'MAP', map_criteria), (SpO2_buckets, 'SpO2', spo2_criteria)]:\n",
    "    for ind in inds:\n",
    "        bucket = buckets[event]\n",
    "        if ind == len(bucket):\n",
    "            eventval = f\"{event}|{bucket[ind-1]}-\"\n",
    "        else:\n",
    "            eventval = f\"{event}|{bucket[ind-1]}-{bucket[ind]}\"\n",
    "        criteria.append(eventval)\n",
    "hr_criteria, map_criteria, spo2_criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe3dee6",
   "metadata": {},
   "source": [
    "TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e99945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/home/mkeoliya/projects/mc-med/data/eventval.parquet')\n",
    "df2 = pd.read_parquet('/home/mkeoliya/projects/mc-med/data/decompensation_demo.parquet')\n",
    "df3 = pd.read_parquet('/home/mkeoliya/projects/mc-med/data/eSOFA_demo.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b23fe922",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(set().union(*df['eventval']))\n",
    "vocab_list += list(df2['Race_str'].unique()) + list(df2['Ethnicity_str'].unique()) + list(df2['Gender_str'].unique()) + list(df2['Age_str'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07d7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = [x for x in vocab_list if x is not None]\n",
    "vocab_list = list(set(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "611f2ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6383e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_list = ['[UNK]', '[BOS]', '[EOS]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n",
    "vocab_list = special_list + vocab_list\n",
    "\n",
    "vocab = {token: idx for idx, token in enumerate(vocab_list)}\n",
    "\n",
    "tokenizer = Tokenizer(models.WordLevel(vocab=vocab, unk_token=\"[UNK]\"))\n",
    "\n",
    "tokenizer.save(os.path.join('data', f'eventval_demo_tokenizer.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arpah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
